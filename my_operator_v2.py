from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.options import Options as EdgeOptions
import os
import time
from urllib.parse import urlparse, unquote
import re

# --- 1. é…ç½®å‚æ•° ---
DOWNLOAD_DIRECTORY = r"D:\VsCodeProjects\Dataset\2Dimages"
FILENAME = "download_urls.txt"
TIMEOUT = 60  # å•æ¬¡ä¸‹è½½æœ€å¤§ç­‰å¾…æ—¶é—´ (ç§’)
POLL_INTERVAL = 1  # æ£€æŸ¥ä¸‹è½½ç›®å½•çš„é—´éš”æ—¶é—´ (ç§’)
MAX_RETRY = 3  # æ¯ä¸ªå›¾ç‰‡çš„æœ€å¤§é‡è¯•æ¬¡æ•°
REFRESH_PAGE_URL = "https://anime-pictures.net/posts?page=4&search_tag=girl&order_by=rating&ldate=4&lang=zh-cn"
COOKIE_REFRESH_WAIT = 5  # åˆ·æ–° Cookie æ—¶çš„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰


def read_download_urls(filename: str) -> list[str]:
    """è¯»å–ä¸‹è½½ URL åˆ—è¡¨"""
    if not os.path.exists(filename):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{filename}' ä¸å­˜åœ¨ã€‚")
        return []

    url_list = []
    print(f"--- æ­£åœ¨è¯»å–æ–‡ä»¶: {filename} ---")
    
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                url = line.strip()
                if url:
                    url_list.append(url)
        
        print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸã€‚æ€»å…±è¯»å–åˆ° {len(url_list)} ä¸ª URLã€‚")
        return url_list
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []


def is_downloading(download_dir: str) -> bool:
    """æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨æ­£åœ¨ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶"""
    for filename in os.listdir(download_dir):
        if filename.endswith(('.crdownload', '.tmp', '.partial')):
            return True
    return False


def wait_for_specific_download_complete(
    download_dir: str, 
    post_id: str, 
    timeout: int = 300, 
    poll_interval: int = 1
) -> bool:
    """
    ç­‰å¾…ä¸‹è½½ç›®å½•ä¸­å‡ºç°åŒ…å«ç‰¹å®š post_id çš„å®Œæ•´æ–‡ä»¶ï¼Œè¡¨ç¤ºä¸‹è½½å®Œæˆã€‚
    
    Args:
        download_dir: ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„
        post_id: æ­£åœ¨ä¸‹è½½å›¾ç‰‡çš„å”¯ä¸€ ID
        timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        poll_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        
    Returns:
        å¦‚æœæ–‡ä»¶åœ¨è¶…æ—¶å‰å‡ºç°åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    start_time = time.time()
    time.sleep(poll_interval * 2)  # åˆå§‹ç­‰å¾…
    
    print(f"  ... æ­£åœ¨ç­‰å¾… ID {post_id} å®Œæ•´ä¸‹è½½...")

    while time.time() - start_time < timeout:
        for filename in os.listdir(download_dir):
            if post_id in filename:
                if not filename.endswith(('.crdownload', '.tmp', '.partial')):
                    time.sleep(1)  # ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
                    return True

        elapsed = int(time.time() - start_time)
        if elapsed % 10 == 0:  # æ¯ 10 ç§’è¾“å‡ºä¸€æ¬¡
            print(f"  ... æ­£åœ¨ç­‰å¾…ä¸‹è½½å®Œæˆ ({elapsed}s / {timeout}s)")
        time.sleep(poll_interval)
        
    print(f"ğŸ”´ é”™è¯¯: ç­‰å¾… ID {post_id} ä¸‹è½½è¶…æ—¶ ({timeout}ç§’)ã€‚")
    return False


def extract_post_id_from_url(url: str) -> str | None:
    """ä» URL ä¸­æå–å¸–å­ ID"""
    match = re.search(r'/download_image/(\d+)-', url)
    if match:
        return match.group(1)
    return None


def check_file_exists(download_dir: str, post_id: str) -> tuple[bool, str | None]:
    """
    æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨ï¼ˆé€šè¿‡ downloaded.txt è®°å½•ï¼‰
    
    Args:
        download_dir: ä¸‹è½½ç›®å½•
        post_id: å›¾ç‰‡ ID
    
    Returns:
        (æ˜¯å¦å­˜åœ¨, æç¤ºä¿¡æ¯)
    """
    downloaded_file = os.path.join(download_dir, "downloaded.txt")
    
    # å¦‚æœ downloaded.txt ä¸å­˜åœ¨ï¼Œè¯´æ˜æ²¡æœ‰ä¸‹è½½è¿‡
    if not os.path.exists(downloaded_file):
        return False, None
    
    try:
        with open(downloaded_file, 'r', encoding='utf-8') as f:
            downloaded_ids = set(line.strip() for line in f if line.strip())
        
        if post_id in downloaded_ids:
            return True, f"å·²è®°å½•åœ¨ downloaded.txt ä¸­"
        else:
            return False, None
            
    except Exception as e:
        print(f"âš ï¸ è¯»å– downloaded.txt æ—¶å‡ºé”™: {e}")
        return False, None

def mark_as_downloaded(download_dir: str, post_id: str):
    """
    å°†æˆåŠŸä¸‹è½½çš„å›¾ç‰‡ ID è®°å½•åˆ° downloaded.txt
    
    Args:
        download_dir: ä¸‹è½½ç›®å½•
        post_id: å›¾ç‰‡ ID
    """
    downloaded_file = os.path.join(download_dir, "downloaded.txt")
    
    try:
        with open(downloaded_file, 'a', encoding='utf-8') as f:
            f.write(f"{post_id}\n")
        print(f"  âœ“ å·²è®°å½• ID: {post_id} åˆ° downloaded.txt")
    except Exception as e:
        print(f"  âš ï¸ è®°å½•åˆ° downloaded.txt æ—¶å‡ºé”™: {e}")

def refresh_cookies(driver: webdriver.Edge, wait_time: int = 5) -> bool:
    """
    åˆ·æ–° Cookiesï¼šé‡æ–°è®¿é—®åˆ—è¡¨é¡µä»¥é€šè¿‡ Cloudflare éªŒè¯
    
    Args:
        driver: Selenium WebDriver å®ä¾‹
        wait_time: ç­‰å¾… Cloudflare éªŒè¯çš„æ—¶é—´ï¼ˆç§’ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸåˆ·æ–°
    """
    try:
        print("ğŸ”„ æ­£åœ¨åˆ·æ–° Cookiesï¼ˆé‡æ–°è®¿é—®åˆ—è¡¨é¡µï¼‰...")
        driver.get(REFRESH_PAGE_URL)
        time.sleep(wait_time)
        
        # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨ Cloudflare éªŒè¯é¡µé¢
        if "Just a moment" in driver.page_source or "Checking your browser" in driver.page_source:
            print("  ... ç­‰å¾… Cloudflare éªŒè¯å®Œæˆ...")
            time.sleep(wait_time * 2)  # é¢å¤–ç­‰å¾…
        
        print("âœ… Cookies åˆ·æ–°æˆåŠŸ")
        return True
        
    except Exception as e:
        print(f"âš ï¸ åˆ·æ–° Cookies æ—¶å‡ºé”™: {e}")
        return False


def download_image_with_retry(
    driver: webdriver.Edge, 
    url: str, 
    post_id: str, 
    download_dir: str,
    index: int,
    total: int,
    max_retry: int = MAX_RETRY
) -> bool:
    """
    å¸¦é‡è¯•æœºåˆ¶çš„å›¾ç‰‡ä¸‹è½½å‡½æ•°
    
    Args:
        driver: Selenium WebDriver å®ä¾‹
        url: å›¾ç‰‡ä¸‹è½½ URL
        post_id: å›¾ç‰‡ ID
        download_dir: ä¸‹è½½ç›®å½•
        index: å½“å‰å›¾ç‰‡ç´¢å¼•
        total: æ€»å›¾ç‰‡æ•°
        max_retry: æœ€å¤§é‡è¯•æ¬¡æ•°
        
    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    for attempt in range(1, max_retry + 1):
        print(f"\nâ–¶ï¸ æ­£åœ¨ä¸‹è½½ç¬¬ {index}/{total} å¼ å›¾ç‰‡ (å°è¯• {attempt}/{max_retry})")
        print(f"   URL: {url}")
        
        try:
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¬¡å°è¯•ï¼Œå…ˆåˆ·æ–° Cookies
            if attempt > 1:
                if not refresh_cookies(driver, COOKIE_REFRESH_WAIT):
                    print(f"âš ï¸ Cookie åˆ·æ–°å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹è½½...")
                time.sleep(2)  # çŸ­æš‚ç­‰å¾…
            
            # è§¦å‘ä¸‹è½½
            driver.get(url)
            
            # ç­‰å¾…ä¸‹è½½å®Œæˆ
            if wait_for_specific_download_complete(
                download_dir, 
                post_id, 
                timeout=TIMEOUT, 
                poll_interval=POLL_INTERVAL
            ):
                print(f"âœ… ç¬¬ {index} å¼ å›¾ç‰‡ä¸‹è½½å®Œæˆ [ID: {post_id}]")

                # â­ æ–°å¢ï¼šè®°å½•åˆ° downloaded.txt
                mark_as_downloaded(download_dir, post_id)
                
                return True
            else:
                print(f"âŒ ç¬¬ {index} å¼ å›¾ç‰‡ä¸‹è½½è¶…æ—¶ (å°è¯• {attempt}/{max_retry})")
                
                # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œç»§ç»­
                if attempt < max_retry:
                    print(f"ğŸ” å‡†å¤‡é‡è¯•...")
                    time.sleep(2)
                    
        except Exception as e:
            print(f"âŒ ä¸‹è½½æ—¶å‘ç”Ÿé”™è¯¯ (å°è¯• {attempt}/{max_retry}): {e}")
            if attempt < max_retry:
                print(f"ğŸ” å‡†å¤‡é‡è¯•...")
                time.sleep(2)
    
    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    print(f"ğŸ”´ ç¬¬ {index} å¼ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Œå·²é‡è¯• {max_retry} æ¬¡ï¼Œè·³è¿‡ [ID: {post_id}]")
    return False


def setup_edge_driver(download_dir: str) -> webdriver.Edge:
    """
    é…ç½®å¹¶å¯åŠ¨ Edge æµè§ˆå™¨ï¼Œå¢å¼ºåæ£€æµ‹èƒ½åŠ›
    """
    options = EdgeOptions()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    options.add_experimental_option("prefs", {
        "download.default_directory": download_dir,
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True
    })
    
    driver = webdriver.Edge(options=options)
    
    # éšè— webdriver ç‰¹å¾
    driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
        'source': '''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            })
        '''
    })
    
    return driver


# --- ä¸»ç¨‹åºæ‰§è¡Œ ---
def main():
    # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
    if not os.path.exists(DOWNLOAD_DIRECTORY):
        os.makedirs(DOWNLOAD_DIRECTORY)
        print(f"ğŸ“ åˆ›å»ºä¸‹è½½ç›®å½•: {DOWNLOAD_DIRECTORY}")

    # 1. è¯»å– URL åˆ—è¡¨
    urls = read_download_urls(FILENAME)

    if not urls:
        print("âŒ æ²¡æœ‰ URL å¯ä¾›ä¸‹è½½ï¼Œç¨‹åºç»“æŸã€‚")
        return

    # 2. å¯åŠ¨æµè§ˆå™¨
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
    driver = setup_edge_driver(DOWNLOAD_DIRECTORY)
    
    try:
        # 3. é¦–æ¬¡è®¿é—®åˆ—è¡¨é¡µï¼Œè·å–åˆå§‹ Cookies
        print(f"\nğŸŒ é¦–æ¬¡è®¿é—®åˆ—è¡¨é¡µä»¥é€šè¿‡ Cloudflare éªŒè¯...")
        driver.get(REFRESH_PAGE_URL)
        time.sleep(COOKIE_REFRESH_WAIT)
        
        if "Just a moment" in driver.page_source or "Checking your browser" in driver.page_source:
            print("  ... ç­‰å¾… Cloudflare éªŒè¯...")
            time.sleep(COOKIE_REFRESH_WAIT * 2)
        
        print("âœ… åˆå§‹åŒ–å®Œæˆ")
        print(f"\n{'='*60}")
        print(f"å¼€å§‹æ‰¹é‡ä¸‹è½½åˆ°ç›®å½•: {DOWNLOAD_DIRECTORY}")
        print(f"æ€»å…± {len(urls)} ä¸ªæ–‡ä»¶")
        print(f"{'='*60}")

        # 4. å¾ªç¯ä¸‹è½½
        success_count = 0
        skip_count = 0
        fail_count = 0
        
        for i, target_url in enumerate(urls, 1):
            # æå– ID
            post_id = extract_post_id_from_url(target_url)
            
            if not post_id:
                print(f"\nâš ï¸ è­¦å‘Š: æ— æ³•ä» URL æå– IDï¼Œè·³è¿‡ ({i}/{len(urls)})")
                skip_count += 1
                continue
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            exists, existing_filename = check_file_exists(DOWNLOAD_DIRECTORY, post_id)
            if exists:
                print(f"\nğŸŸ¢ è·³è¿‡: æ–‡ä»¶å·²å­˜åœ¨ ({i}/{len(urls)}) [ID: {post_id}]")
                print(f"   æœ¬åœ°æ–‡ä»¶å: {existing_filename}")
                skip_count += 1
                continue
            
            # ä¸‹è½½å›¾ç‰‡ï¼ˆå¸¦é‡è¯•ï¼‰
            if download_image_with_retry(
                driver, 
                target_url, 
                post_id, 
                DOWNLOAD_DIRECTORY,
                i,
                len(urls),
                MAX_RETRY
            ):
                success_count += 1
            else:
                fail_count += 1
        
        # 5. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"   âœ… æˆåŠŸ: {success_count} ä¸ª")
        print(f"   ğŸŸ¢ è·³è¿‡: {skip_count} ä¸ª")
        print(f"   âŒ å¤±è´¥: {fail_count} ä¸ª")
        print(f"   ğŸ“ æ€»è®¡: {len(urls)} ä¸ª")
        print(f"{'='*60}")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # 6. æ¸…ç†å’Œé€€å‡º
        print("\nğŸ§¹ æ­£åœ¨æ¸…ç†èµ„æº...")
        driver.quit()
        print("âœ… æ‰€æœ‰ä¸‹è½½ä»»åŠ¡å·²å¤„ç†å®Œæ¯•ã€‚")


if __name__ == "__main__":
    main()