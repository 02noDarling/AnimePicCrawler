from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.edge.options import Options as EdgeOptions
import os
import time
from urllib.parse import urlparse, unquote # å¯¼å…¥ç”¨äºè§£æURLçš„åº“
import re

# --- 1. é…ç½®å‚æ•° ---
# ç¡®ä¿è¿™ä¸ªè·¯å¾„ä¸ options ä¸­è®¾ç½®çš„è·¯å¾„ä¸€è‡´
DOWNLOAD_DIRECTORY = r"D:\VsCodeProjects\Dataset\2Dimages"
FILENAME = "download_urls.txt"
TIMEOUT = 300  # æœ€å¤§ç­‰å¾…ä¸‹è½½å®Œæˆçš„æ—¶é—´ (ç§’)
POLL_INTERVAL = 1  # æ£€æŸ¥ä¸‹è½½ç›®å½•çš„é—´éš”æ—¶é—´ (ç§’)


def read_download_urls(filename: str) -> list[str]:
    # (ä¿æŒä½ åŸæœ‰çš„ read_download_urls å‡½æ•°ä¸å˜)
    if not os.path.exists(filename):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ '{filename}' ä¸å­˜åœ¨ã€‚")
        return []

    url_list = []
    print(f"--- æ­£åœ¨è¯»å–æ–‡ä»¶: {filename} ---")
    
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                url = line.strip()
                if url:
                    url_list.append(url)
        
        print(f"âœ… æ–‡ä»¶è¯»å–æˆåŠŸã€‚æ€»å…±è¯»å–åˆ° {len(url_list)} ä¸ª URLã€‚")
        return url_list
        
    except Exception as e:
        print(f"âš ï¸ è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return []


def is_downloading(download_dir: str) -> bool:
    """
    æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨æ­£åœ¨ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚ .crdownload, .tmpï¼‰ã€‚
    """
    for filename in os.listdir(download_dir):
        # æ£€æŸ¥å¸¸è§çš„ä¸´æ—¶æ–‡ä»¶æ‰©å±•å
        if filename.endswith(('.crdownload', '.tmp', '.partial')):
            return True
    return False

def wait_for_download_complete(download_dir: str, timeout: int = 60, poll_interval: int = 1) -> bool:
    """
    ç­‰å¾…ä¸‹è½½ç›®å½•ä¸­æ²¡æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œè¡¨ç¤ºä¸‹è½½å®Œæˆã€‚
    """
    start_time = time.time()
    
    # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼Œç¡®ä¿æ–‡ä»¶å¼€å§‹ä¸‹è½½
    # è¿™ä¸€æ­¥å¯¹äºæ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸´æ—¶æ–‡ä»¶æ˜¯å¿…è¦çš„ï¼Œç»™æµè§ˆå™¨ä¸€ä¸ªå¼€å§‹ä¸‹è½½çš„æ—¶é—´
    time.sleep(poll_interval) 

    while is_downloading(download_dir):
        if time.time() - start_time > timeout:
            print(f"ğŸ”´ é”™è¯¯: ç­‰å¾…ä¸‹è½½è¶…æ—¶ ({timeout}ç§’)ã€‚")
            return False
        
        print(f"  ... æ­£åœ¨ç­‰å¾…ä¸‹è½½å®Œæˆ ({int(time.time() - start_time)}s / {timeout}s)")
        time.sleep(poll_interval)
        
    # å¢åŠ ä¸€ä¸ªçŸ­æš‚çš„ç­‰å¾…ï¼Œä»¥ç¡®ä¿æ–‡ä»¶ç³»ç»Ÿæ“ä½œå®Œæˆ
    time.sleep(1) 
    return True

def extract_post_id_from_url(url: str) -> str | None:
    """
    ä» anime-pictures çš„ä¸‹è½½ URL ä¸­æå–å¸–å­ IDã€‚
    """
    match = re.search(r'/download_image/(\d+)-', url)
    if match:
        return match.group(1)
    return None

# --- ä¿®æ”¹åçš„å‡½æ•°ç­¾åå’Œé€»è¾‘ ---
def wait_for_specific_download_complete(
    download_dir: str, 
    post_id: str, 
    timeout: int = 300, 
    poll_interval: int = 1
) -> bool:
    """
    ç­‰å¾…ä¸‹è½½ç›®å½•ä¸­å‡ºç°åŒ…å«ç‰¹å®š post_id çš„å®Œæ•´æ–‡ä»¶ï¼Œè¡¨ç¤ºä¸‹è½½å®Œæˆã€‚
    
    Args:
        download_dir: ä¸‹è½½æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        post_id: æ­£åœ¨ä¸‹è½½å›¾ç‰‡çš„å”¯ä¸€ IDã€‚
        timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ã€‚
        poll_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰ã€‚
        
    Returns:
        å¦‚æœæ–‡ä»¶åœ¨è¶…æ—¶å‰å‡ºç°åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    start_time = time.time()
    
    # å¢åŠ ä¸€ä¸ªåˆå§‹ç­‰å¾…ï¼Œç¡®ä¿æµè§ˆå™¨å¼€å§‹å†™å…¥æ–‡ä»¶
    time.sleep(poll_interval * 2) 
    
    print(f"  ... æ­£åœ¨ç­‰å¾… ID {post_id} å®Œæ•´ä¸‹è½½åˆ° {download_dir} ...")

    while time.time() - start_time < timeout:
        
        # éå†ä¸‹è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for filename in os.listdir(download_dir):
            # 1. æ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«è¯¥ ID
            if post_id in filename:
                # 2. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸æ˜¯ä¸´æ—¶æ–‡ä»¶ (.crdownload æˆ– .tmp)
                if not filename.endswith(('.crdownload', '.tmp', '.partial')):
                    # æ‰¾åˆ°äº†å®Œæ•´çš„ç›®æ ‡æ–‡ä»¶
                    time.sleep(1) # å¢åŠ çŸ­æš‚ç­‰å¾…ï¼Œç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
                    return True

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´æ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…
        print(f"  ... æ­£åœ¨ç­‰å¾…ä¸‹è½½å®Œæˆ ({int(time.time() - start_time)}s / {timeout}s)")
        time.sleep(poll_interval)
        
    # è¶…æ—¶é€€å‡º
    print(f"ğŸ”´ é”™è¯¯: ç­‰å¾… ID {post_id} ä¸‹è½½è¶…æ—¶ ({timeout}ç§’)ã€‚")
    return False

def extract_post_id_from_url(url: str) -> str | None:
    """
    ä» anime-pictures çš„ä¸‹è½½ URL ä¸­æå–å¸–å­ IDã€‚
    URL æ ¼å¼é€šå¸¸ä¸º: .../download_image/ID-widthxheight-tags...
    """
    # åŒ¹é… /download_image/ åé¢çš„ç¬¬ä¸€ä¸ªæ•°å­—ä¸² (å³ ID)
    match = re.search(r'/download_image/(\d+)-', url)
    if match:
        return match.group(1)
    return None

# --- ä¸»ç¨‹åºæ‰§è¡Œ ---

# ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
if not os.path.exists(DOWNLOAD_DIRECTORY):
    os.makedirs(DOWNLOAD_DIRECTORY)
    print(f"åˆ›å»ºä¸‹è½½ç›®å½•: {DOWNLOAD_DIRECTORY}")

# 1. è¯»å– URL åˆ—è¡¨
urls = read_download_urls(FILENAME)

if not urls:
    print("æ²¡æœ‰ URL å¯ä¾›ä¸‹è½½ï¼Œç¨‹åºç»“æŸã€‚")
else:
    # 2. é…ç½® Edge æµè§ˆå™¨é€‰é¡¹
    options = EdgeOptions()
    options.add_argument("--start-maximized")

    options.add_experimental_option("prefs", {
        "download.default_directory": DOWNLOAD_DIRECTORY,
        "download.prompt_for_download": False,
        "download.directory_upgrade": True 
    })
    
    # 3. å¯åŠ¨é©±åŠ¨
    driver = webdriver.Edge(options=options)
    
    # é¦–å…ˆè®¿é—®ä¸€ä¸ªæ­£å¸¸çš„é¡µé¢
    driver.get("https://anime-pictures.net/posts?page=4&search_tag=girl&order_by=rating&ldate=4&lang=zh-cn")
    
    print(f"\n--- å¼€å§‹æ‰¹é‡ä¸‹è½½åˆ°ç›®å½•: {DOWNLOAD_DIRECTORY} ---")

    # 4. å¾ªç¯ä¸‹è½½å¹¶ç­‰å¾… (å¢åŠ è·³è¿‡é€»è¾‘)
    for i, target_url in enumerate(urls):
        
        # --- æ–°å¢çš„è·³è¿‡é€»è¾‘ START ---
        path = urlparse(target_url).path
        filename_with_encoding = os.path.basename(path)
        # URLä¸­çš„æ–‡ä»¶åé€šå¸¸æ˜¯URLç¼–ç è¿‡çš„ï¼Œéœ€è¦è§£ç 
        expected_filename = unquote(filename_with_encoding) 
        if not expected_filename.startswith("ANIME-PICTURES.NET_-_"):
            expected_filename = "ANIME-PICTURES.NET_-_" + expected_filename
            
        post_id = extract_post_id_from_url(target_url)
    
        if not post_id:
            print(f"âš ï¸ è­¦å‘Š: æ— æ³•ä» URL æå– IDï¼Œè·³è¿‡æ­¤ URL ({i+1}/{len(urls)}): {target_url}")
            continue
            
        # b. æ£€æŸ¥ä¸‹è½½ç›®å½•ä¸­æ˜¯å¦å­˜åœ¨åŒ…å«æ­¤ ID çš„æ–‡ä»¶
        found_existing = False
        
        # éå†ä¸‹è½½ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        for filename in os.listdir(DOWNLOAD_DIRECTORY):
            # æ£€æŸ¥æ–‡ä»¶åä¸­æ˜¯å¦åŒ…å«è¯¥ ID
            # å³ä½¿æ–‡ä»¶åå¼€å¤´æ˜¯ ANIME-PICTURES.NET_- æˆ–å…¶ä»–ï¼Œåªè¦åŒ…å« ID å°±è®¤ä¸ºå·²å­˜åœ¨
            if post_id in filename:
                # ç¡®ä¿è¿™ä¸æ˜¯ä¸€ä¸ªä¸´æ—¶æ–‡ä»¶ (.crdownload æˆ– .tmp)
                if not filename.endswith(('.crdownload', '.tmp', '.partial')):
                    print(f"ğŸŸ¢ è·³è¿‡: æ–‡ä»¶å·²å­˜åœ¨ ({i+1}/{len(urls)}) [ID: {post_id}]ï¼Œæœ¬åœ°æ–‡ä»¶å: {filename}")
                    found_existing = True
                    break
        
        if found_existing:
            continue # è·³è¿‡å½“å‰å¾ªç¯ï¼Œè¿›å…¥ä¸‹ä¸€ä¸ª URL
        
        # --- æ–°å¢çš„è·³è¿‡é€»è¾‘ END ---
        
        print(f"\nâ–¶ï¸ æ­£åœ¨ä¸‹è½½ç¬¬ {i+1}/{len(urls)} å¼ å›¾ç‰‡: {expected_filename}")
        
        # è§¦å‘ä¸‹è½½
        driver.get(target_url)
        
        # ç­‰å¾…å½“å‰ä¸‹è½½å®Œæˆ
        # if wait_for_download_complete(DOWNLOAD_DIRECTORY, timeout=TIMEOUT, poll_interval=POLL_INTERVAL):
        #     print(f"âœ… ç¬¬ {i+1} å¼ å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚")
        # else:
        #     print(f"âŒ ç¬¬ {i+1} å¼ å›¾ç‰‡ä¸‹è½½å¤±è´¥æˆ–è¶…æ—¶ï¼Œè·³è¿‡ã€‚")

        if wait_for_specific_download_complete(
            DOWNLOAD_DIRECTORY, 
            post_id, 
            timeout=TIMEOUT, 
            poll_interval=POLL_INTERVAL
        ):
            print(f"âœ… ç¬¬ {i+1} å¼ å›¾ç‰‡ä¸‹è½½å®Œæˆã€‚")
        else:
            print(f"âŒ ç¬¬ {i+1} å¼ å›¾ç‰‡ä¸‹è½½å¤±è´¥æˆ–è¶…æ—¶ï¼Œè·³è¿‡ã€‚")
            
    # 5. æ¸…ç†å’Œé€€å‡º
    driver.quit()
    print("\næ‰€æœ‰ä¸‹è½½ä»»åŠ¡å·²å¤„ç†å®Œæ¯•ã€‚")